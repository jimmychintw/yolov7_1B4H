#!/usr/bin/env python3
"""
æ¸¬è©¦ YOLOv7-Tiny MultiHead åœ¨ 320x320 è§£æåº¦ä¸‹çš„æ”¯æ´
å°ˆé–€é‡å° COCO 2017 æ•¸æ“šé›†è¨­è¨ˆ
"""

import torch
import torch.nn as nn
from models.yolo import Model, MultiHeadDetect
from utils.loss_multihead import ComputeLossMultiHead
from utils.multihead_utils import MultiHeadConfig
import numpy as np

def test_320x320_resolution():
    """æ¸¬è©¦ 320x320 è§£æåº¦çš„å®Œæ•´æ”¯æ´"""
    
    print("="*70)
    print("YOLOv7-Tiny MultiHead 320Ã—320 è§£æåº¦æ¸¬è©¦ (COCO 2017)")
    print("="*70)
    
    # 1. æ¸¬è©¦ç‰¹å¾µåœ–å°ºå¯¸è¨ˆç®—
    print("\n1. é©—è­‰ 320Ã—320 ç‰¹å¾µåœ–å°ºå¯¸...")
    input_size = 320
    strides = [8, 16, 32]  # YOLOv7-Tiny æ¨™æº– stride
    
    feature_maps = []
    for stride in strides:
        fm_size = input_size // stride
        feature_maps.append((fm_size, fm_size))
        print(f"   P{int(np.log2(stride))}/{stride}: {fm_size}Ã—{fm_size} = {fm_size*fm_size} ç¶²æ ¼")
    
    # 2. æ¸¬è©¦éŒ¨æ¡†é…ç½®ï¼ˆé‡å° 320Ã—320 å„ªåŒ–ï¼‰
    print("\n2. 320Ã—320 å°ˆç”¨éŒ¨æ¡†é…ç½®...")
    
    # åŸå§‹ 640Ã—640 éŒ¨æ¡†
    anchors_640 = [
        [10,13, 16,30, 33,23],      # P3/8
        [30,61, 62,45, 59,119],     # P4/16
        [116,90, 156,198, 373,326]  # P5/32
    ]
    
    # ç¸®æ”¾åˆ° 320Ã—320 (æ¯”ä¾‹: 320/640 = 0.5)
    scale = 320 / 640
    anchors_320 = []
    for layer_anchors in anchors_640:
        scaled = [int(a * scale) for a in layer_anchors]
        anchors_320.append(scaled)
    
    print("   åŸå§‹ 640Ã—640 éŒ¨æ¡†:")
    for i, anchors in enumerate(anchors_640):
        print(f"     P{3+i}: {anchors}")
    
    print("\n   ç¸®æ”¾åˆ° 320Ã—320 éŒ¨æ¡†:")
    for i, anchors in enumerate(anchors_320):
        print(f"     P{3+i}: {anchors}")
    
    # 3. æ¸¬è©¦ MultiHeadDetect åœ¨ 320Ã—320 ä¸‹çš„é‹ä½œ
    print("\n3. æ¸¬è©¦ MultiHeadDetect å±¤...")
    
    # YOLOv7-Tiny åœ¨ 320Ã—320 çš„é€šé“é…ç½®
    ch = (128, 256, 512)  # P3, P4, P5 é€šé“æ•¸
    
    # å‰µå»º MultiHeadDetect
    det = MultiHeadDetect(nc=80, anchors=anchors_320, ch=ch)
    det.stride = torch.tensor(strides).float()
    
    # å‰µå»º 320Ã—320 è¼¸å…¥çš„ç‰¹å¾µåœ–
    batch_size = 2
    x = [
        torch.randn(batch_size, ch[0], 40, 40),  # P3/8: 320/8 = 40
        torch.randn(batch_size, ch[1], 20, 20),  # P4/16: 320/16 = 20
        torch.randn(batch_size, ch[2], 10, 10),  # P5/32: 320/32 = 10
    ]
    
    print(f"   è¼¸å…¥ç‰¹å¾µåœ–å½¢ç‹€:")
    for i, feat in enumerate(x):
        print(f"     P{3+i}: {feat.shape}")
    
    # æ¸¬è©¦å‰å‘å‚³æ’­
    det.train()
    reg_obj, cls = det(x)
    
    print(f"\n   âœ… è¨“ç·´æ¨¡å¼è¼¸å‡º:")
    print(f"     reg_obj: {[r.shape for r in reg_obj]}")
    print(f"     cls heads: {len(cls)} å€‹é ­")
    
    det.eval()
    pred, _ = det(x)
    print(f"\n   âœ… æ¨ç†æ¨¡å¼è¼¸å‡º:")
    print(f"     é æ¸¬å¼µé‡: {pred.shape}")
    print(f"     ç¸½éŒ¨æ¡†æ•¸: {pred.shape[1]}")
    
    # 4. æ¸¬è©¦å°ç‰©é«”æª¢æ¸¬èƒ½åŠ›
    print("\n4. å°ç‰©é«”æª¢æ¸¬èƒ½åŠ›åˆ†æ...")
    
    # è¨ˆç®—æ¯å€‹æª¢æ¸¬å±¤çš„æ„Ÿå—é‡
    print("   æ„Ÿå—é‡åˆ†æ (320Ã—320):")
    total_anchors = 0
    for i, (stride, fm_size) in enumerate(zip(strides, feature_maps)):
        n_anchors = 3 * fm_size[0] * fm_size[1]
        total_anchors += n_anchors
        min_obj = stride * 2  # æœ€å°å¯æª¢æ¸¬ç‰©é«”å¤§å°ï¼ˆç¶“é©—å€¼ï¼‰
        max_obj = stride * 16  # æœ€å¤§å¯æª¢æ¸¬ç‰©é«”å¤§å°ï¼ˆç¶“é©—å€¼ï¼‰
        print(f"     P{3+i}/{stride}: {n_anchors:,} éŒ¨æ¡†, ç‰©é«”ç¯„åœ {min_obj}-{max_obj} pixels")
    
    print(f"   ç¸½éŒ¨æ¡†æ•¸: {total_anchors:,}")
    
    # 5. COCO 2017 é¡åˆ¥åˆ†çµ„æ¸¬è©¦
    print("\n5. COCO 2017 å¤šé ­é¡åˆ¥åˆ†çµ„...")
    
    config = MultiHeadConfig('data/coco-multihead.yaml')
    
    print(f"   æª¢æ¸¬é ­æ•¸é‡: {config.n_heads}")
    print(f"   é¡åˆ¥ç¸½æ•¸: {config.nc}")
    
    for head_id in range(config.n_heads):
        head_info = config.head_assignments[head_id]
        print(f"\n   Head {head_id} ({head_info['name']}):")
        print(f"     é¡åˆ¥æ•¸: {len(head_info['classes'])}")
        print(f"     æ¬Šé‡: {head_info.get('weight', 1.0):.2f}")
        print(f"     Supercategory: {head_info.get('supercategory', 'N/A')}")
    
    # 6. æå¤±è¨ˆç®—æ¸¬è©¦ï¼ˆ320Ã—320 ç‰¹å®šï¼‰
    print("\n6. æ¸¬è©¦æå¤±è¨ˆç®— (320Ã—320)...")
    
    class SimpleModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.model = nn.ModuleList([det])
            self.hyp = {
                'box': 0.05, 'cls': 0.5, 'obj': 1.0,
                'anchor_t': 3.5,  # é™ä½åˆ° 3.5 for 320Ã—320
                'cls_pw': 1.0, 'obj_pw': 1.0,
                'fl_gamma': 0.0, 'label_smoothing': 0.0
            }
            self.gr = 1.0
    
    model = SimpleModel()
    compute_loss = ComputeLossMultiHead(model)
    
    # å‰µå»ºé©åˆ 320Ã—320 çš„ç›®æ¨™ï¼ˆæ­¸ä¸€åŒ–åº§æ¨™ï¼‰
    targets = torch.tensor([
        [0, 0, 0.5, 0.5, 0.05, 0.05],   # å°ç‰©é«” (16Ã—16 pixels)
        [0, 2, 0.2, 0.2, 0.03, 0.03],   # æ›´å°ç‰©é«” (10Ã—10 pixels)
        [1, 14, 0.8, 0.8, 0.15, 0.15],  # ä¸­ç­‰ç‰©é«” (48Ã—48 pixels)
        [1, 56, 0.6, 0.6, 0.25, 0.25],  # å¤§ç‰©é«” (80Ã—80 pixels)
    ])
    
    model.train()
    pred = model.model[0](x)
    loss, loss_items = compute_loss(pred, targets)
    
    print(f"   âœ… æå¤±è¨ˆç®—æˆåŠŸ:")
    print(f"     ç¸½æå¤±: {loss.item():.4f}")
    print(f"     box={loss_items[0]:.4f}, obj={loss_items[1]:.4f}, cls={loss_items[2]:.4f}")
    
    # 7. æ€§èƒ½é ä¼°
    print("\n7. 320Ã—320 æ€§èƒ½é ä¼°...")
    
    # åƒæ•¸çµ±è¨ˆ
    det_params = sum(p.numel() for p in det.parameters())
    print(f"   æª¢æ¸¬å±¤åƒæ•¸: {det_params:,}")
    
    # FLOPs ä¼°ç®—ï¼ˆç°¡åŒ–è¨ˆç®—ï¼‰
    flops_per_conv = 0
    for i, (c, fm) in enumerate(zip(ch, feature_maps)):
        # æ¯å€‹é ­çš„å·ç©é‹ç®—
        flops = c * 85 * 3 * fm[0] * fm[1] * 4  # 4 heads
        flops_per_conv += flops
    
    print(f"   æª¢æ¸¬å±¤ FLOPs: ~{flops_per_conv/1e9:.2f} GFLOPs")
    
    # è¨˜æ†¶é«”ä½”ç”¨ä¼°ç®—
    memory_mb = det_params * 4 / 1024 / 1024  # FP32
    print(f"   æª¢æ¸¬å±¤è¨˜æ†¶é«”: ~{memory_mb:.1f} MB (FP32)")
    
    print("\n" + "="*70)
    print("âœ… YOLOv7-Tiny å®Œå…¨æ”¯æ´ 320Ã—320 è§£æåº¦èˆ‡ COCO 2017ï¼")
    print("="*70)
    
    return True

def test_coco2017_compatibility():
    """æ¸¬è©¦ COCO 2017 æ•¸æ“šé›†ç›¸å®¹æ€§"""
    
    print("\n\nCOCO 2017 æ•¸æ“šé›†ç›¸å®¹æ€§æ¸¬è©¦")
    print("-"*70)
    
    # è¼‰å…¥é…ç½®
    config = MultiHeadConfig('data/coco-multihead.yaml')
    
    # COCO 2017 çµ±è¨ˆ
    print("\nğŸ“Š COCO 2017 æ•¸æ“šé›†çµ±è¨ˆ:")
    print("   è¨“ç·´é›†: 118,287 å¼µåœ–ç‰‡")
    print("   é©—è­‰é›†: 5,000 å¼µåœ–ç‰‡")
    print("   æ¸¬è©¦é›†: 40,670 å¼µåœ–ç‰‡")
    print("   é¡åˆ¥æ•¸: 80")
    print("   ç¸½æ¨™è¨»æ¡†: >1.5M")
    
    # é©—è­‰é¡åˆ¥è¦†è“‹
    print("\nğŸ“‹ é¡åˆ¥è¦†è“‹é©—è­‰:")
    coco_classes = set(range(80))
    assigned_classes = set()
    
    for head_id in range(config.n_heads):
        classes = set(config.get_classes_for_head(head_id))
        assigned_classes.update(classes)
    
    missing = coco_classes - assigned_classes
    extra = assigned_classes - coco_classes
    
    if missing:
        print(f"   âŒ ç¼ºå°‘é¡åˆ¥: {missing}")
    else:
        print(f"   âœ… æ‰€æœ‰ 80 å€‹ COCO é¡åˆ¥éƒ½å·²åˆ†é…")
    
    if extra:
        print(f"   âŒ é¡å¤–é¡åˆ¥: {extra}")
    
    # é¡åˆ¥åˆ†ä½ˆçµ±è¨ˆ
    print("\nğŸ“ˆ é æœŸé¡åˆ¥åˆ†ä½ˆ (åŸºæ–¼ COCO 2017):")
    distributions = {
        'person & sports': 35,
        'vehicle & outdoor': 25,
        'animal & food': 20,
        'furniture & appliance': 20
    }
    
    for head_id in range(config.n_heads):
        head_info = config.head_assignments[head_id]
        supercategory = head_info.get('supercategory', 'unknown')
        expected = distributions.get(supercategory, 0)
        print(f"   Head {head_id}: ~{expected}% çš„è¨“ç·´æ¨£æœ¬")
    
    print("\nâœ… COCO 2017 å®Œå…¨ç›¸å®¹ï¼")

def compare_resolutions():
    """æ¯”è¼ƒä¸åŒè§£æåº¦çš„å½±éŸ¿"""
    
    print("\n\nè§£æåº¦æ¯”è¼ƒåˆ†æ")
    print("-"*70)
    
    resolutions = [320, 416, 512, 640]
    
    print("\nğŸ“ ä¸åŒè§£æåº¦çš„ç‰¹å¾µåœ–å¤§å°:")
    print("\n   è§£æåº¦ | P3/8  | P4/16 | P5/32 | ç¸½éŒ¨æ¡†æ•¸")
    print("   " + "-"*50)
    
    for res in resolutions:
        p3 = (res // 8) ** 2 * 3
        p4 = (res // 16) ** 2 * 3
        p5 = (res // 32) ** 2 * 3
        total = p3 + p4 + p5
        
        print(f"   {res:3d}Ã—{res:<3d} | {p3:5,} | {p4:5,} | {p5:5,} | {total:7,}")
    
    print("\nğŸ’¡ è§€å¯Ÿ:")
    print("   - 320Ã—320 çš„éŒ¨æ¡†æ•¸æ˜¯ 640Ã—640 çš„ 1/4")
    print("   - è¼ƒä½è§£æåº¦æ›´é©åˆé‚Šç·£è¨­å‚™éƒ¨ç½²")
    print("   - éœ€è¦èª¿æ•´ anchor_t åƒæ•¸ä»¥é©æ‡‰å°ç‰©é«”")

if __name__ == "__main__":
    # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
    success = test_320x320_resolution()
    
    if success:
        test_coco2017_compatibility()
        compare_resolutions()
        
        print("\n\n" + "="*70)
        print("ğŸ“ ç¸½çµï¼š")
        print("="*70)
        print("1. âœ… YOLOv7-Tiny å®Œå…¨æ”¯æ´ 320Ã—320 è§£æåº¦")
        print("2. âœ… COCO 2017 æ‰€æœ‰ 80 é¡åˆ¥æ­£ç¢ºåˆ†é…åˆ° 4 å€‹æª¢æ¸¬é ­")
        print("3. âœ… é‡å° 320Ã—320 å„ªåŒ–çš„éŒ¨æ¡†é…ç½®")
        print("4. âœ… æå¤±è¨ˆç®—æ”¯æ´å°ç‰©é«”æª¢æ¸¬")
        print("5. âœ… MultiHead æ¶æ§‹å®Œå…¨ç›¸å®¹")
        
        print("\nğŸš€ ä½¿ç”¨æŒ‡å—ï¼š")
        print("1. ä½¿ç”¨ cfg/training/yolov7-tiny-multihead-proper.yaml")
        print("2. è¨­å®š --img-size 320")
        print("3. èª¿æ•´ hyp.anchor_t = 3.5 (é‡å°å°ç‰©é«”)")
        print("4. ä½¿ç”¨ data/coco-multihead.yaml ä½œç‚ºæ•¸æ“šé…ç½®")
        print("5. è¨“ç·´æŒ‡ä»¤ï¼š")
        print("   python train.py --img 320 --batch 64 \\")
        print("                   --cfg cfg/training/yolov7-tiny-multihead-proper.yaml \\")
        print("                   --data data/coco-multihead.yaml \\")
        print("                   --device 0")